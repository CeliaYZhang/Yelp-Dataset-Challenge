{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "nbpresent": {
     "id": "946947ae-8c8a-4596-8edf-737b0db60fe6"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "\n",
    "import imageio\n",
    "import loading\n",
    "import tqdm\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import svm\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Lambda, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "8cd62661-4480-4c87-9a52-6224dc66d451"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"DEFINE CONSTANTS HERE\"\"\"\n",
    "\n",
    "DATA_PATH           = '../data'\n",
    "VISUALIZATION_PATH  = '../visualization'\n",
    "\n",
    "MISSING_VALUE       = '<NONE>'       # Used for the 'neighborhood' and 'city' attributes.\n",
    "DEFAULT_NEI_P       = 0.2            # Default percentile of neighborhoods to keep.\n",
    "DEFAULT_CITY_P      = 0.1            # Default percentile of cities to keep.\n",
    "DEFAULT_ATT_P       = 1.0            # Default percentile of attributes to keep.\n",
    "DEFAULT_CAT_P       = 0.5            # Default percentile of categories to keep.\n",
    "DEFAULT_HRS_P       = 1.0            # Default percentile of hours to keep.\n",
    "\n",
    "TIME_GRANULARITY    = 1              # Granularity (ticks/hr) of time calculations, factor of 60. \n",
    "\n",
    "SLICE_BY            = ['Restaurants']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "291b4ee3-21ef-443a-8b73-4c02ba5b46cb"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Loads the json file of the given dataset name.\"\"\"\n",
    "def load(name):\n",
    "  start = time.time()\n",
    "  data = loading.read_df_from_json('%s/%s.json' % (DATA_PATH, name))\n",
    "  print 'time to load \\'%s\\': %.3fs' % (name, time.time() - start)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "abd975c5-2824-44cd-87ad-9556d53f7c99"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Cleans the business dataset.\"\"\"\n",
    "def clean_business(business):\n",
    "  print 'Replacing %s with %s.' % (u'Montréal', u'Montreal')\n",
    "  business['city'].replace(to_replace=u'Montréal', \n",
    "                           value=u'Montreal',\n",
    "                           inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "04ac22ac-3fa4-423a-bc85-82070c57e991"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Plots all businesses on the world map for visualization purposes.\"\"\"\n",
    "def plot_business(business):\n",
    "  points = business[['latitude', 'longitude']]\n",
    "\n",
    "  img = imageio.imread(VISUALIZATION_PATH + '/raw_map.jpg').astype('int64')\n",
    "  img = img / 4               # Dim map.\n",
    "  img = img[8:-8,8:-8,:]      # Clip borders.\n",
    "  H, W, _ = img.shape\n",
    "  \n",
    "  scalar = 10                 # Amount to add to each channel.\n",
    "  delta = np.zeros((H, W), dtype='int64')\n",
    "  \n",
    "  def get_xy(latitude, longitude):\n",
    "    x = (W - 1) * (180.0 + longitude) / 360.0\n",
    "    y = (H - 1) * (90.0 - latitude) / 180.0\n",
    "    return int(x), int(y)\n",
    "\n",
    "  for row in points.itertuples():\n",
    "    latitude, longitude = row.latitude, row.longitude\n",
    "    if not math.isnan(latitude) and not math.isnan(longitude):\n",
    "      x, y = get_xy(latitude, longitude)\n",
    "      delta[y,x] += scalar\n",
    "\n",
    "  img += np.expand_dims(delta, axis=-1).repeat(3, axis=-1)\n",
    "  img = img.clip(0, 255).astype('uint8')\n",
    "  \n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "eec66196-2d62-43f9-83c7-bf6a4fb555b3"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Returns the count_dict as a sorted list.\"\"\"\n",
    "def to_list(count_dict):\n",
    "  return sorted([(k, count_dict[k]) for k in count_dict], key=lambda v: v[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "1ef7dedb-efaa-49d1-8edc-6150727a921f"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Converts a dict of counts (key, int) into a list of top features.\n",
    "\n",
    "   Takes either top N (int) features, or top PERCENTILE (float) by occurrence.\n",
    "\n",
    "   Example usage:\n",
    "     top_features(count_dict, 0.1)                  # Returns top 10% of elements.\n",
    "     top_features(count_dict, top_n=5)              # Returns top 5 elements.\n",
    "\"\"\"\n",
    "def top_features(count_dict, percentile=None, n=None, verbose=True):\n",
    "  if n is None:\n",
    "    if percentile is None:\n",
    "      raise Exception\n",
    "    n = int(percentile * len(count_dict))\n",
    "\n",
    "  l = heapq.nlargest(n, count_dict, key=lambda k: count_dict[k])\n",
    "  \n",
    "  if verbose:\n",
    "    percentage = 0.0 if not len(count_dict) else 100.0 * n / len(count_dict)\n",
    "    params = (n, len(count_dict), percentage, 0 if not l else count_dict[l[-1]])\n",
    "    print 'Took %d elements out of %d (%2.1f%%). Cutoff was >= %d.' % params\n",
    "    \n",
    "  return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "653df377-dfa1-4b2c-8656-280f84949f2d"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Methods for converting a tuple from itertuples() to a feature list.\"\"\"\n",
    "\n",
    "# Return neighborhood concatenated with city, or MISSING_VALUE if empty. \n",
    "def get_neighborhood(tup):\n",
    "  assert type(tup.neighborhood) is unicode\n",
    "  return [tup.neighborhood + '/' + tup.city if tup.neighborhood else MISSING_VALUE]\n",
    "\n",
    "# Return city, or MISSING_VALUE if empty.\n",
    "def get_city(tup):\n",
    "  assert type(tup.city) is unicode\n",
    "  return [tup.city if tup.city else MISSING_VALUE]\n",
    "\n",
    "# Recursively process attributes dict to get indicators for all attributes.\n",
    "def get_attributes(tup):\n",
    "  def _recurse(attributes, prefix):\n",
    "    assert type(attributes) is dict\n",
    "    l = []\n",
    "    for k, v in attributes.items():\n",
    "      if type(v) is bool:\n",
    "        l.append(prefix + '/' + k)\n",
    "      elif type(v) is unicode:\n",
    "        l.append(prefix + '/' + k + '/' + v)\n",
    "      elif type(v) is int:\n",
    "        l.append(prefix + '/' + k + '/' + str(v))\n",
    "      elif type(v) is dict:\n",
    "        l += _recurse(attributes[k], prefix=k)\n",
    "      else:\n",
    "        assert False  # Invalid type in attributes.\n",
    "    return l\n",
    "  return _recurse(tup.attributes, prefix='')\n",
    "\n",
    "# Return categories.\n",
    "def get_categories(tup):\n",
    "  assert type(tup.categories) is list\n",
    "  return tup.categories\n",
    "\n",
    "\"\"\"Helper methods for get_hours(), which determines which ticks of time the business is open.\n",
    "   Each tick of time corresponds to an index in [0, _max_ticks()).\n",
    "\n",
    "   In _time_to_dt_index, ROUND_UP determines what happens when the time falls\n",
    "   in between ticks. By default, the time is rounded up.\n",
    "\"\"\"\n",
    "# An ordering of the days of the week, and a map from str --> index\n",
    "_day_order = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "_day_index = {d:i for i, d in enumerate(_day_order)}\n",
    "\n",
    "# Maximum number of ticks\n",
    "def _max_ticks():\n",
    "  return 7 * 24 * TIME_GRANULARITY\n",
    "\n",
    "# Given day of the week and time, returns the corresponding tick in [0, _max_ticks()).\n",
    "def _time_to_dt_index(day, time, round_up=True):\n",
    "  [hour, minutes] = time.split(':')\n",
    "  hour_index = int(hour) * TIME_GRANULARITY\n",
    "  min_index  = int(minutes) / (60 / TIME_GRANULARITY)\n",
    "  if round_up and int(minutes) % (60 / TIME_GRANULARITY) > 0:\n",
    "    min_index += 1\n",
    "  return _day_index[day] * 24 * TIME_GRANULARITY + hour_index + min_index\n",
    "\n",
    "# Cache the string corresponding to each tick of time.\n",
    "_timestr_cache = ['%s/%02d:%02d' % (_day_order[day], hour, min_index * 60 / TIME_GRANULARITY)\n",
    "                  for day in range(0, 7)\n",
    "                  for hour in range(0, 24)\n",
    "                  for min_index in range(0, TIME_GRANULARITY)]\n",
    "\n",
    "def get_hours(tup):\n",
    "  assert type(tup.hours) is dict\n",
    "  l = []\n",
    "  for day, hours in tup.hours.items():\n",
    "    open_time, close_time = hours.split('-')\n",
    "    open_index = _time_to_dt_index(day, open_time)\n",
    "    close_index = _time_to_dt_index(day, close_time)\n",
    "\n",
    "    assert 0 <= open_index and close_index <= _max_ticks()\n",
    "    \n",
    "    # Handle the case where close_index is for the following day.\n",
    "    if close_index <= open_index:\n",
    "      close_index += 24 * TIME_GRANULARITY\n",
    "    \n",
    "    # Append the slice of the _time_str_cache, handling wrap-around appropriately.\n",
    "    l += _timestr_cache[open_index:min(close_index, _max_ticks())]\n",
    "    if close_index > _max_ticks():\n",
    "      l += _timestr_cache[0:close_index - _max_ticks()]\n",
    "      \n",
    "  return l\n",
    "\n",
    "# Function to retrieve all features of a given row tuple.\n",
    "all_fns = [get_neighborhood, get_city, get_attributes, get_categories, get_hours]\n",
    "def get_all_features(tup):\n",
    "  all_features = set([])\n",
    "  for fn in all_fns:\n",
    "    all_features |= set(fn(tup))\n",
    "  return all_features\n",
    "\n",
    "# Returns the value to regress on for the row tuple.\n",
    "def get_target(tup):\n",
    "  return float(tup.stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "e0be7c98-dad3-447c-97a2-d6c186d78da5"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Get the features that we will use for \n",
    "   neighborhoods, cities, attributes, categories.\n",
    "\n",
    "   By default, take:\n",
    "     TOP 20% OF neighborhoods\n",
    "     TOP 10% OF cities\n",
    "         ALL OF attributes\n",
    "     TOP 50% OF categories\n",
    "         ALL OF hours\n",
    "   \n",
    "   Returns a length 6 tuple:\n",
    "     (nei_set, city_set, att_set, cat_set, hours_set, debug_vals)\n",
    "\"\"\"\n",
    "def get_feature_sets(business, slice_by=[],\n",
    "                     percentiles=[DEFAULT_NEI_P, DEFAULT_CITY_P, DEFAULT_ATT_P, \n",
    "                                  DEFAULT_CAT_P, DEFAULT_HRS_P]):\n",
    "  def has_required_features(all_features):\n",
    "    all_features_set = set([])\n",
    "    for features in all_features:\n",
    "      all_features_set |= set(features)\n",
    "    for f in slice_by:\n",
    "      if f not in all_features_set:\n",
    "        return False\n",
    "    return True\n",
    "  \n",
    "  fn_counts_percentile = zip(all_fns, [defaultdict(int) for _ in range(len(all_fns))], percentiles)\n",
    "\n",
    "  for tup in tqdm.tqdm(business.itertuples()):\n",
    "    all_features = [fn(tup) for fn, _, _ in fn_counts_percentile]\n",
    "    if not has_required_features(all_features):\n",
    "      continue\n",
    "    for features, (_, counts, _) in zip(all_features, fn_counts_percentile):\n",
    "      for f in features:\n",
    "        counts[f] += 1\n",
    "\n",
    "  debug_val = [(fn.__name__, to_list(counts)) for fn, counts, _ in fn_counts_percentile]\n",
    "  \n",
    "  return [top_features(counts, percentile) for fn, counts, percentile in fn_counts_percentile], debug_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "289f6d77-a27a-4cf4-8559-edf3f068896d"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Gets a mapping from feature name to feature index and vice versa.\"\"\"\n",
    "def get_feature_maps(feature_sets, start_index=0):  \n",
    "  # Assert that there are no overlapping names.\n",
    "  union = set([])\n",
    "  for s in feature_sets:\n",
    "    union |= set(s)\n",
    "  assert len(union) == sum([len(s) for s in feature_sets])\n",
    "\n",
    "  name_to_index, index_to_name = {}, {}\n",
    "  for i, feature in enumerate(union):\n",
    "    name_to_index[feature] = start_index + i\n",
    "    index_to_name[start_index + i] = feature\n",
    "\n",
    "  return name_to_index, index_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slice_by_feature(x, y, name_to_index, feature_name):\n",
    "  if feature_name not in name_to_index:\n",
    "    print 'Feature %s not found.' % feature_name\n",
    "    return x, y\n",
    "  feature_index = name_to_index[feature_name]\n",
    "  indices = np.where(x[:,feature_index] == 1)\n",
    "  return x[indices], y[indices]\n",
    "\n",
    "def slice_by_features(x, y, name_to_index, slice_by):\n",
    "  for feature_name in slice_by:\n",
    "    x, y = slice_by_feature(x, y, name_to_index, feature_name)\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "ec08aa75-b5c0-495a-92a0-7cfea7e776ce"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Creates a list of data points for multivariate linear regression.\"\"\"\n",
    "def get_training_data(business, name_to_index, slice_by=[]):\n",
    "  x = np.zeros((business.shape[0], len(name_to_index)), dtype='float32')\n",
    "  y = np.zeros(business.shape[0], dtype='float32')\n",
    "  \n",
    "  for i, tup in tqdm.tqdm(enumerate(business.itertuples())):\n",
    "    all_features = get_all_features(tup)\n",
    "    for f in all_features:\n",
    "      if f in name_to_index:\n",
    "        x[i,name_to_index[f]] = 1\n",
    "    y[i] = get_target(tup)\n",
    "  \n",
    "  return slice_by_features(x, y, name_to_index, slice_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "50857f70-79cf-475d-9c4e-739505c9f2ab"
    }
   },
   "source": [
    "Run business regression.\n",
    "\n",
    "NOT USABLE:\n",
    "- business_id\n",
    "- name\n",
    "\n",
    "PROBABLY NOT USABLE:\n",
    "- latitude\n",
    "- longitude\n",
    "- postal code\n",
    "- address\n",
    "- is_open\n",
    "- review_count\n",
    "- state\n",
    "\n",
    "REGRESS ON:\n",
    "- stars  (1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5)\n",
    "\n",
    "FEATURES:\n",
    "- neighborhood/city  --> indicators (~20%)\n",
    "- city               --> indicators (~10%)\n",
    "- attributes         --> indicators (process types differently, each has a separate indicator)\n",
    "- categories         --> indicators (~50%)\n",
    "- hours              --> indicators for every hour/half hour/quarter of the hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "284f8122-8e46-413c-9d39-f07431deb2e8"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to load 'business': 7.847s\n",
      "Replacing Montréal with Montreal.\n"
     ]
    }
   ],
   "source": [
    "business = load('business')\n",
    "clean_business(business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "3af4073c-1b36-4790-bc22-9e549e7f02a7"
    }
   },
   "outputs": [],
   "source": [
    "# img = plot_business(business)\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "# imageio.imsave(VISUALIZATION_PATH + '/business_map.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "nbpresent": {
     "id": "acd359bb-dccd-42b8-b6ff-d6fa3eb5c008"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156639it [00:12, 12692.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 110 elements out of 550 (20.0%). Cutoff was >= 45.\n",
      "Took 73 elements out of 734 (9.9%). Cutoff was >= 68.\n",
      "Took 100 elements out of 100 (100.0%). Cutoff was >= 3.\n",
      "Took 325 elements out of 651 (49.9%). Cutoff was >= 5.\n",
      "Took 168 elements out of 168 (100.0%). Cutoff was >= 1373.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SLICE_BY = ['Restaurants']\n",
    "\n",
    "feature_sets, debug_val = get_feature_sets(business, slice_by=SLICE_BY, \n",
    "                                           percentiles=[0.2, 0.1, 1, 0.5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Burgers', 4236),\n",
       " (u'Italian', 4411),\n",
       " (u'Pizza', 5652),\n",
       " (u'American (Traditional)', 5737),\n",
       " (u'Fast Food', 5792),\n",
       " (u'Sandwiches', 5864),\n",
       " (u'Bars', 6690),\n",
       " (u'Nightlife', 6969),\n",
       " (u'Food', 9599),\n",
       " (u'Restaurants', 51613)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_val[3][1][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "3c317a23-36fd-4efa-8cdb-920fe50be73b"
    }
   },
   "outputs": [],
   "source": [
    "feature_maps = get_feature_maps(feature_sets)\n",
    "name_to_index, index_to_name = feature_maps  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "nbpresent": {
     "id": "402fdf70-91e4-4be3-b179-262296e16195"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156639it [00:14, 10610.09it/s]\n"
     ]
    }
   ],
   "source": [
    "x, y = get_training_data(business, name_to_index, slice_by=SLICE_BY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing by: ['Restaurants']\n",
      "Samples in slice: 156639\n",
      "\n",
      "Intercept = 3.58061851914\n",
      "\n",
      "/BusinessAcceptsBitcoin 0.342346757621\n",
      "/GoodForKids 0.172942719921\n",
      "/WheelchairAccessible 0.153347807609\n",
      "/ByAppointmentOnly 0.151098584623\n",
      "/NoiseLevel/quiet 0.138159549628\n",
      "/RestaurantsAttire/dressy 0.136932100057\n",
      "/DogsAllowed 0.124039173798\n",
      "/BikeParking 0.112387147115\n",
      "/Alcohol/beer_and_wine 0.111477314322\n",
      "/BYOBCorkage/yes_corkage 0.11132263277\n",
      "HairSpecializesIn/asian 0.0987743316461\n",
      "HairSpecializesIn/africanamerican 0.0987743316458\n",
      "HairSpecializesIn/straightperms 0.0987743316458\n",
      "/GoodForDancing 0.0857124420639\n",
      "/BYOBCorkage/no 0.0829163971722\n",
      "/AcceptsInsurance 0.0809592772045\n",
      "/BusinessAcceptsCreditCards 0.0804764951161\n",
      "BusinessParking/street 0.0738306952085\n",
      "BusinessParking/garage 0.0738306952074\n",
      "BusinessParking/valet 0.073830695207\n",
      "...\n",
      "/Smoking/outdoor -0.0783826344536\n",
      "Ambience/divey -0.0907304870965\n",
      "/RestaurantsTableService -0.116634177\n",
      "/NoiseLevel/loud -0.142102922107\n",
      "Ambience/hipster -0.143509417396\n",
      "/RestaurantsAttire/formal -0.15831270321\n",
      "/RestaurantsGoodForGroups -0.190578381579\n",
      "/RestaurantsPriceRange2/1 -0.191217694244\n",
      "/RestaurantsAttire/casual -0.195520978763\n",
      "/RestaurantsPriceRange2/2 -0.203852189701\n",
      "/AgesAllowed/21plus -0.213940432383\n",
      "BusinessParking/validated -0.23995575567\n",
      "/AgesAllowed/allages -0.290491486935\n",
      "/WiFi/paid -0.310460538149\n",
      "/RestaurantsPriceRange2/3 -0.336356131175\n",
      "/NoiseLevel/very_loud -0.343732623083\n",
      "/AgesAllowed/18plus -0.423861450562\n",
      "/DriveThru -0.434049186856\n",
      "/RestaurantsPriceRange2/4 -0.477770855585\n",
      "/AgesAllowed/19plus -0.490695626793\n",
      "\n",
      "0.884701326139\n"
     ]
    }
   ],
   "source": [
    "print 'Slicing by:', SLICE_BY\n",
    "print 'Samples in slice:', len(x)\n",
    "print\n",
    "\n",
    "reg = linear_model.Ridge(alpha=0.5)\n",
    "reg.fit(x, y)\n",
    "\n",
    "print 'Intercept =', reg.intercept_\n",
    "print\n",
    "\n",
    "N = 20\n",
    "coefs = [(index_to_name[i], c) for i, c in enumerate(reg.coef_)]\n",
    "for n, c in heapq.nlargest(N, coefs, key=lambda v: v[1]):\n",
    "  print n, c\n",
    "print '...'\n",
    "for n, c in reversed(heapq.nsmallest(N, coefs, key=lambda v: v[1])):\n",
    "  print n, c\n",
    "print\n",
    "\n",
    "y_hat = reg.predict(x)\n",
    "print mean_squared_error(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39954.0\n",
      "3.47999\n"
     ]
    }
   ],
   "source": [
    "f = '/RestaurantsTableService'\n",
    "print np.sum(x[:,name_to_index[f]])\n",
    "print np.mean(y[np.where(x[:,name_to_index[f]] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing by: ['Restaurants', 'Las Vegas']\n",
      "Samples in slice: 51613\n",
      "\n",
      "Time taken: 530.648411989\n",
      "\n",
      "Intercept = 3.50246176322\n",
      "\n",
      "Food Trucks 0.475872730223\n",
      "Latin American 0.308654181542\n",
      "Vegan 0.27386211335\n",
      "Hawaiian 0.216550200952\n",
      "/NoiseLevel/quiet 0.201479185074\n",
      "Specialty Food 0.197366301258\n",
      "Caterers 0.19032927206\n",
      "Cafes 0.182996497465\n",
      "Mediterranean 0.181079378919\n",
      "Hot Dogs 0.176944669293\n",
      "/BusinessAcceptsBitcoin 0.162573155289\n",
      "/BikeParking 0.161776427853\n",
      "Vegetarian 0.137435724471\n",
      "Cocktail Bars 0.135960628156\n",
      "/NoiseLevel/average 0.133369270457\n",
      "/DogsAllowed 0.128246777394\n",
      "Delis 0.126258413843\n",
      "/DriveThru 0.113874243678\n",
      "Ice Cream & Frozen Yogurt 0.107004670696\n",
      "Juice Bars & Smoothies 0.102695444847\n",
      "...\n",
      "/RestaurantsGoodForGroups -0.0389996523818\n",
      "/CoatCheck -0.0422329484661\n",
      "/NoiseLevel/loud -0.0422953017803\n",
      "Diners -0.0433000821345\n",
      "Steakhouses -0.063128292076\n",
      "/RestaurantsPriceRange2/2 -0.0765789787396\n",
      "/HasTV -0.0789639951918\n",
      "/RestaurantsTableService -0.0960308418842\n",
      "Pizza -0.109437203201\n",
      "/RestaurantsAttire/casual -0.112638057894\n",
      "American (Traditional) -0.135468926132\n",
      "/BusinessAcceptsCreditCards -0.15460326884\n",
      "Sports Bars -0.162875916711\n",
      "Chinese -0.205288643641\n",
      "Tex-Mex -0.277978554426\n",
      "Burgers -0.287116737984\n",
      "Chicken Wings -0.311857831026\n",
      "BusinessParking/validated -0.338757585245\n",
      "Buffets -0.427050869437\n",
      "Fast Food -0.637135782265\n",
      "\n",
      "0.50697698911\n"
     ]
    }
   ],
   "source": [
    "N = len(x)\n",
    "x_slice = x[:N]\n",
    "y_slice = y[:N]\n",
    "\n",
    "print 'Slicing by:', SLICE_BY\n",
    "print 'Samples in slice:', len(x_slice)\n",
    "print\n",
    "\n",
    "start = time.time()\n",
    "reg = svm.SVR(kernel='linear', cache_size=10000)\n",
    "reg.fit(x_slice, y_slice)\n",
    "print 'Time taken:', time.time() - start\n",
    "print\n",
    "\n",
    "print 'Intercept =', reg.intercept_[0]\n",
    "print\n",
    "\n",
    "N = 20\n",
    "coefs = [(index_to_name[i], c) for i, c in enumerate(reg.coef_[0])]\n",
    "for n, c in heapq.nlargest(N, coefs, key=lambda v: v[1]):\n",
    "  print n, c\n",
    "print '...'\n",
    "for n, c in reversed(heapq.nsmallest(N, coefs, key=lambda v: v[1])):\n",
    "  print n, c\n",
    "print\n",
    "\n",
    "y_hat = reg.predict(x_slice)\n",
    "print mean_squared_error(y_slice, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing by: ['Restaurants', 'Las Vegas']\n",
      "Samples in slice: 51613\n",
      "\n",
      "Intercept = 3.37994172865\n",
      "\n",
      "Food 0.190584\n",
      "/DogsAllowed 0.143745\n",
      "/BikeParking 0.102871\n",
      "/NoiseLevel/quiet 0.0657489\n",
      "/WheelchairAccessible 0.0384163\n",
      "/NoiseLevel/average 0.029308\n",
      "/Alcohol/beer_and_wine 0.0136793\n",
      "Cafes 0.0081211\n",
      "/Caters 0.0\n",
      "/Corkage 0.0\n",
      "...\n",
      "/Corkage 0.0\n",
      "/Caters 0.0\n",
      "/NoiseLevel/loud -0.00766474\n",
      "/RestaurantsPriceRange2/2 -0.00887873\n",
      "Chinese -0.0341109\n",
      "Pizza -0.0405149\n",
      "American (Traditional) -0.0650737\n",
      "Chicken Wings -0.130297\n",
      "Burgers -0.133637\n",
      "Fast Food -0.451302\n",
      "\n",
      "0.539111\n"
     ]
    }
   ],
   "source": [
    "print 'Slicing by:', SLICE_BY\n",
    "print 'Samples in slice:', len(x)\n",
    "print\n",
    "\n",
    "reg = linear_model.Lasso(alpha=0.01)\n",
    "reg.fit(x, y)\n",
    "\n",
    "print 'Intercept =', reg.intercept_\n",
    "print\n",
    "\n",
    "N = 10\n",
    "coefs = [(index_to_name[i], c) for i, c in enumerate(reg.coef_)]\n",
    "for n, c in heapq.nlargest(N, coefs, key=lambda v: v[1]):\n",
    "  print n, c\n",
    "print '...'\n",
    "for n, c in reversed(heapq.nsmallest(N, coefs, key=lambda v: v[1])):\n",
    "  print n, c\n",
    "print\n",
    "\n",
    "y_hat = reg.predict(x)\n",
    "print mean_squared_error(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8443746448840965"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(business['is_open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the value to regress on for the row tuple.\n",
    "def get_target(tup):\n",
    "  return float(tup.is_open)\n",
    "x, y = get_training_data(business, name_to_index, slice_by=SLICE_BY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing by: ['Restaurants', 'Las Vegas']\n",
      "Samples in slice: 51613\n",
      "\n",
      "Time taken: 258.449704885\n",
      "\n",
      "Intercept = 0.999929675129\n",
      "\n",
      "/BikeParking 1.9997699162\n",
      "Ambience/romantic 0.285666837635\n",
      "Ambience/intimate 0.285666837635\n",
      "Ambience/trendy 0.285666837635\n",
      "Ambience/touristy 0.285666837635\n",
      "Ambience/casual 0.285666837635\n",
      "Ambience/upscale 0.285666837635\n",
      "Ambience/classy 0.285666837635\n",
      "Event Planning & Services 0.00132228196326\n",
      "Fast Food 0.00117647360533\n",
      "/RestaurantsTakeOut 0.000818843758562\n",
      "/RestaurantsDelivery 0.000498512307871\n",
      "/RestaurantsReservations 0.000405198766737\n",
      "Chicken Wings 0.000296510237379\n",
      "/GoodForDancing 0.00019484718853\n",
      "/GoodForKids 0.000190825523486\n",
      "Food Trucks 0.000177822532715\n",
      "Pizza 0.000126994878592\n",
      "/RestaurantsGoodForGroups 0.00011773958747\n",
      "Food Delivery Services 8.87794796975e-05\n",
      "...\n",
      "BusinessParking/street -0.000104530556225\n",
      "BusinessParking/valet -0.000104530556225\n",
      "BusinessParking/lot -0.000104530556225\n",
      "BusinessParking/garage -0.000104530556225\n",
      "Nightlife -0.000126712550558\n",
      "Hot Dogs -0.000130612256777\n",
      "/WheelchairAccessible -0.000164014896418\n",
      "/NoiseLevel/quiet -0.000184691060062\n",
      "/Alcohol/none -0.000249446930786\n",
      "/Alcohol/beer_and_wine -0.000257315915984\n",
      "/RestaurantsPriceRange2/3 -0.000331250338903\n",
      "/Alcohol/full_bar -0.000350262856093\n",
      "/RestaurantsPriceRange2/2 -0.00039003700946\n",
      "/RestaurantsPriceRange2/1 -0.000478377862407\n",
      "/OutdoorSeating -0.000531824389906\n",
      "BusinessParking/validated -0.000686174754858\n",
      "/BusinessAcceptsCreditCards -0.000967071481295\n",
      "Caterers -0.00123545710412\n",
      "/RestaurantsTableService -1.99819729901\n",
      "Ambience/hipster -1.99935338314\n",
      "\n",
      "0.190243\n",
      "0.809757231705\n",
      "0.748978\n"
     ]
    }
   ],
   "source": [
    "N = len(x)\n",
    "x_slice = x[:N]\n",
    "y_slice = y[:N]\n",
    "\n",
    "print 'Slicing by:', SLICE_BY\n",
    "print 'Samples in slice:', len(x_slice)\n",
    "print\n",
    "\n",
    "start = time.time()\n",
    "reg = svm.SVC(kernel='linear', cache_size=10000)\n",
    "reg.fit(x_slice, y_slice)\n",
    "print 'Time taken:', time.time() - start\n",
    "print\n",
    "\n",
    "print 'Intercept =', reg.intercept_[0]\n",
    "print\n",
    "\n",
    "N = 20\n",
    "coefs = [(index_to_name[i], c) for i, c in enumerate(reg.coef_[0])]\n",
    "for n, c in heapq.nlargest(N, coefs, key=lambda v: v[1]):\n",
    "  print n, c\n",
    "print '...'\n",
    "for n, c in reversed(heapq.nsmallest(N, coefs, key=lambda v: v[1])):\n",
    "  print n, c\n",
    "print\n",
    "\n",
    "y_hat = reg.predict(x_slice)\n",
    "print mean_squared_error(y_slice, y_hat)\n",
    "print reg.score(x_slice, y_slice)\n",
    "print np.mean(y_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/RestaurantsPriceRange2/4\n",
      "/RestaurantsPriceRange2/3\n",
      "/RestaurantsPriceRange2/2\n",
      "/RestaurantsPriceRange2/1\n"
     ]
    }
   ],
   "source": [
    "for k in name_to_index.keys():\n",
    "  if 'Price' in k:\n",
    "    print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing by: ['Restaurants']\n",
      "Samples in slice: 51613\n",
      "\n",
      "Shape: (51613, 776)\n",
      "Classes: 9\n",
      "\n",
      "Train on 41290 samples, validate on 10323 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 1.7927 - acc: 0.2614 - val_loss: 1.7033 - val_acc: 0.2961\n",
      "Epoch 2/50\n",
      " - 2s - loss: 1.7113 - acc: 0.2923 - val_loss: 1.6807 - val_acc: 0.3055\n",
      "Epoch 3/50\n",
      " - 2s - loss: 1.6836 - acc: 0.2996 - val_loss: 1.6686 - val_acc: 0.2994\n",
      "Epoch 4/50\n",
      " - 2s - loss: 1.6699 - acc: 0.3062 - val_loss: 1.6697 - val_acc: 0.3010\n",
      "Epoch 5/50\n",
      " - 2s - loss: 1.6595 - acc: 0.3109 - val_loss: 1.6493 - val_acc: 0.3067\n",
      "Epoch 6/50\n",
      " - 2s - loss: 1.6492 - acc: 0.3103 - val_loss: 1.6566 - val_acc: 0.3042\n",
      "Epoch 7/50\n",
      " - 2s - loss: 1.6437 - acc: 0.3154 - val_loss: 1.6477 - val_acc: 0.3105\n",
      "Epoch 8/50\n",
      " - 2s - loss: 1.6359 - acc: 0.3149 - val_loss: 1.6342 - val_acc: 0.3166\n",
      "Epoch 9/50\n",
      " - 2s - loss: 1.6304 - acc: 0.3184 - val_loss: 1.6352 - val_acc: 0.3084\n",
      "Epoch 10/50\n",
      " - 2s - loss: 1.6248 - acc: 0.3242 - val_loss: 1.6343 - val_acc: 0.3167\n",
      "Epoch 11/50\n",
      " - 2s - loss: 1.6188 - acc: 0.3246 - val_loss: 1.6425 - val_acc: 0.3154\n",
      "Epoch 12/50\n",
      " - 2s - loss: 1.6129 - acc: 0.3271 - val_loss: 1.6266 - val_acc: 0.3208\n",
      "Epoch 13/50\n",
      " - 2s - loss: 1.6071 - acc: 0.3276 - val_loss: 1.6264 - val_acc: 0.3224\n",
      "Epoch 14/50\n",
      " - 2s - loss: 1.6024 - acc: 0.3315 - val_loss: 1.6409 - val_acc: 0.3078\n",
      "Epoch 15/50\n",
      " - 2s - loss: 1.5964 - acc: 0.3375 - val_loss: 1.6724 - val_acc: 0.3038\n",
      "Epoch 16/50\n",
      " - 2s - loss: 1.5942 - acc: 0.3333 - val_loss: 1.6329 - val_acc: 0.3148\n",
      "Epoch 17/50\n",
      " - 2s - loss: 1.5865 - acc: 0.3370 - val_loss: 1.6404 - val_acc: 0.3145\n",
      "Epoch 18/50\n",
      " - 2s - loss: 1.5803 - acc: 0.3399 - val_loss: 1.6317 - val_acc: 0.3219\n",
      "Epoch 19/50\n",
      " - 2s - loss: 1.5764 - acc: 0.3378 - val_loss: 1.6397 - val_acc: 0.3189\n",
      "Epoch 20/50\n",
      " - 2s - loss: 1.5724 - acc: 0.3448 - val_loss: 1.6335 - val_acc: 0.3253\n",
      "Epoch 21/50\n",
      " - 2s - loss: 1.5681 - acc: 0.3457 - val_loss: 1.6314 - val_acc: 0.3213\n",
      "Epoch 22/50\n",
      " - 2s - loss: 1.5610 - acc: 0.3470 - val_loss: 1.6392 - val_acc: 0.3142\n",
      "Epoch 23/50\n",
      " - 2s - loss: 1.5571 - acc: 0.3502 - val_loss: 1.6381 - val_acc: 0.3159\n",
      "Epoch 24/50\n",
      " - 2s - loss: 1.5544 - acc: 0.3538 - val_loss: 1.6394 - val_acc: 0.3189\n",
      "Epoch 25/50\n",
      " - 2s - loss: 1.5468 - acc: 0.3526 - val_loss: 1.6409 - val_acc: 0.3222\n",
      "Epoch 26/50\n",
      " - 2s - loss: 1.5414 - acc: 0.3555 - val_loss: 1.6411 - val_acc: 0.3200\n",
      "Epoch 27/50\n",
      " - 2s - loss: 1.5348 - acc: 0.3589 - val_loss: 1.6522 - val_acc: 0.3112\n",
      "Epoch 28/50\n",
      " - 2s - loss: 1.5318 - acc: 0.3618 - val_loss: 1.6502 - val_acc: 0.3221\n",
      "Epoch 29/50\n",
      " - 2s - loss: 1.5243 - acc: 0.3658 - val_loss: 1.6471 - val_acc: 0.3146\n",
      "Epoch 30/50\n",
      " - 2s - loss: 1.5184 - acc: 0.3668 - val_loss: 1.6513 - val_acc: 0.3209\n",
      "Epoch 31/50\n",
      " - 2s - loss: 1.5125 - acc: 0.3690 - val_loss: 1.6594 - val_acc: 0.3145\n",
      "Epoch 32/50\n",
      " - 2s - loss: 1.5080 - acc: 0.3724 - val_loss: 1.6510 - val_acc: 0.3212\n",
      "Epoch 33/50\n",
      " - 2s - loss: 1.5041 - acc: 0.3767 - val_loss: 1.6683 - val_acc: 0.3205\n",
      "Epoch 34/50\n",
      " - 2s - loss: 1.4982 - acc: 0.3792 - val_loss: 1.6605 - val_acc: 0.3178\n",
      "Epoch 35/50\n",
      " - 2s - loss: 1.4907 - acc: 0.3794 - val_loss: 1.6607 - val_acc: 0.3238\n",
      "Epoch 36/50\n",
      " - 2s - loss: 1.4849 - acc: 0.3810 - val_loss: 1.6690 - val_acc: 0.3158\n",
      "Epoch 37/50\n",
      " - 2s - loss: 1.4782 - acc: 0.3842 - val_loss: 1.6679 - val_acc: 0.3166\n",
      "Epoch 38/50\n",
      " - 2s - loss: 1.4749 - acc: 0.3868 - val_loss: 1.6762 - val_acc: 0.3189\n",
      "Epoch 39/50\n",
      " - 2s - loss: 1.4662 - acc: 0.3926 - val_loss: 1.6802 - val_acc: 0.3129\n",
      "Epoch 40/50\n",
      " - 2s - loss: 1.4636 - acc: 0.3903 - val_loss: 1.6963 - val_acc: 0.3176\n",
      "Epoch 41/50\n",
      " - 2s - loss: 1.4571 - acc: 0.3924 - val_loss: 1.7015 - val_acc: 0.3069\n",
      "Epoch 42/50\n",
      " - 2s - loss: 1.4486 - acc: 0.3992 - val_loss: 1.6925 - val_acc: 0.3115\n",
      "Epoch 43/50\n",
      " - 2s - loss: 1.4417 - acc: 0.4002 - val_loss: 1.6974 - val_acc: 0.3205\n",
      "Epoch 44/50\n",
      " - 2s - loss: 1.4387 - acc: 0.4049 - val_loss: 1.6951 - val_acc: 0.3185\n",
      "Epoch 45/50\n",
      " - 2s - loss: 1.4295 - acc: 0.4067 - val_loss: 1.6967 - val_acc: 0.3149\n",
      "Epoch 46/50\n",
      " - 2s - loss: 1.4256 - acc: 0.4057 - val_loss: 1.7057 - val_acc: 0.3155\n",
      "Epoch 47/50\n",
      " - 2s - loss: 1.4182 - acc: 0.4145 - val_loss: 1.7243 - val_acc: 0.3131\n",
      "Epoch 48/50\n",
      " - 2s - loss: 1.4139 - acc: 0.4161 - val_loss: 1.7100 - val_acc: 0.3115\n",
      "Epoch 49/50\n",
      " - 2s - loss: 1.4064 - acc: 0.4189 - val_loss: 1.7190 - val_acc: 0.3105\n",
      "Epoch 50/50\n",
      " - 2s - loss: 1.4060 - acc: 0.4178 - val_loss: 1.7273 - val_acc: 0.3166\n"
     ]
    }
   ],
   "source": [
    "print 'Slicing by:', SLICE_BY\n",
    "print 'Samples in slice:', len(x)\n",
    "print\n",
    "\n",
    "classes = 9\n",
    "\n",
    "print 'Shape:', x.shape\n",
    "print 'Classes:', classes\n",
    "print\n",
    "\n",
    "def one_hot(y):\n",
    "  y_new = np.zeros((len(y), classes))\n",
    "  for i in range(classes):\n",
    "    val = 1.0 + i * 0.5\n",
    "    y_new[:,i] = (y == val)\n",
    "  return y_new\n",
    "\n",
    "def get_model():\n",
    "  model = Sequential()\n",
    "  model.add(Dense(units=512, activation='relu', input_dim=x.shape[1]))\n",
    "  model.add(Dropout(rate=0.3))\n",
    "  model.add(Dense(units=512, activation='relu'))\n",
    "  model.add(Dropout(rate=0.3))\n",
    "  model.add(Dense(units=256, activation='relu'))\n",
    "  model.add(Dropout(rate=0.3))\n",
    "  model.add(Dense(units=128, activation='relu'))\n",
    "  model.add(Dense(units=classes, activation='softmax'))\n",
    "\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adadelta',\n",
    "                metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "def shuffle(x, y):\n",
    "  assert(x.shape[0] == y.shape[0])\n",
    "  split = x.shape[1]\n",
    "  z = np.hstack((x, y))\n",
    "  z = np.random.permutation(z)\n",
    "  return z[:,:split], z[:,split:]\n",
    "  \n",
    "\n",
    "x_train, y_train = shuffle(x, one_hot(y))\n",
    "model = get_model()\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=50, \n",
    "                    batch_size=128, \n",
    "                    validation_split=0.2,\n",
    "                    verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing by: ['Restaurants']\n",
      "Samples in slice: 51613\n",
      "\n",
      "Shape: (51613, 776)\n",
      "Classes: 9\n",
      "\n",
      "Train on 41290 samples, validate on 10323 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.5275 - val_loss: 4.5066\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.8616 - val_loss: 4.0309\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.7137 - val_loss: 2.6677\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.6246 - val_loss: 1.6842\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.5697 - val_loss: 1.0374\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.5413 - val_loss: 0.8929\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.5277 - val_loss: 0.7991\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.5230 - val_loss: 0.7243\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.5179 - val_loss: 0.6914\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.5138 - val_loss: 0.7435\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.5101 - val_loss: 0.7025\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.5041 - val_loss: 0.6520\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.4907 - val_loss: 0.6232\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.4829 - val_loss: 0.6089\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.4766 - val_loss: 0.5709\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.4721 - val_loss: 0.6351\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.4705 - val_loss: 0.6311\n",
      "Epoch 18/100\n",
      " - 2s - loss: 0.4668 - val_loss: 0.6298\n",
      "Epoch 19/100\n",
      " - 2s - loss: 0.4651 - val_loss: 0.6156\n",
      "Epoch 20/100\n",
      " - 2s - loss: 0.4626 - val_loss: 0.5599\n",
      "Epoch 21/100\n",
      " - 2s - loss: 0.4621 - val_loss: 0.6028\n",
      "Epoch 22/100\n",
      " - 2s - loss: 0.4603 - val_loss: 0.6415\n",
      "Epoch 23/100\n",
      " - 2s - loss: 0.4575 - val_loss: 0.6011\n",
      "Epoch 24/100\n",
      " - 2s - loss: 0.4548 - val_loss: 0.6580\n",
      "Epoch 25/100\n",
      " - 2s - loss: 0.4523 - val_loss: 0.6456\n",
      "Epoch 26/100\n",
      " - 2s - loss: 0.4527 - val_loss: 0.6878\n",
      "Epoch 27/100\n",
      " - 2s - loss: 0.4508 - val_loss: 0.6243\n",
      "Epoch 28/100\n",
      " - 2s - loss: 0.4506 - val_loss: 0.5984\n",
      "Epoch 29/100\n",
      " - 2s - loss: 0.4461 - val_loss: 0.6165\n",
      "Epoch 30/100\n",
      " - 2s - loss: 0.4454 - val_loss: 0.6532\n",
      "Epoch 31/100\n",
      " - 2s - loss: 0.4452 - val_loss: 0.6393\n",
      "Epoch 32/100\n",
      " - 2s - loss: 0.4438 - val_loss: 0.6375\n",
      "Epoch 33/100\n",
      " - 2s - loss: 0.4402 - val_loss: 0.6540\n",
      "Epoch 34/100\n",
      " - 2s - loss: 0.4407 - val_loss: 0.5994\n",
      "Epoch 35/100\n",
      " - 2s - loss: 0.4364 - val_loss: 0.5989\n",
      "Epoch 36/100\n",
      " - 2s - loss: 0.4365 - val_loss: 0.6094\n",
      "Epoch 37/100\n",
      " - 2s - loss: 0.4361 - val_loss: 0.5947\n",
      "Epoch 38/100\n",
      " - 2s - loss: 0.4330 - val_loss: 0.6532\n",
      "Epoch 39/100\n",
      " - 2s - loss: 0.4344 - val_loss: 0.6109\n",
      "Epoch 40/100\n",
      " - 2s - loss: 0.4323 - val_loss: 0.6733\n",
      "Epoch 41/100\n",
      " - 2s - loss: 0.4283 - val_loss: 0.6840\n",
      "Epoch 42/100\n",
      " - 2s - loss: 0.4284 - val_loss: 0.6280\n",
      "Epoch 43/100\n",
      " - 2s - loss: 0.4260 - val_loss: 0.6535\n",
      "Epoch 44/100\n",
      " - 2s - loss: 0.4253 - val_loss: 0.6421\n",
      "Epoch 45/100\n",
      " - 2s - loss: 0.4260 - val_loss: 0.6623\n",
      "Epoch 46/100\n",
      " - 2s - loss: 0.4251 - val_loss: 0.6360\n",
      "Epoch 47/100\n",
      " - 2s - loss: 0.4217 - val_loss: 0.6639\n",
      "Epoch 48/100\n",
      " - 2s - loss: 0.4225 - val_loss: 0.6499\n",
      "Epoch 49/100\n",
      " - 2s - loss: 0.4223 - val_loss: 0.6510\n",
      "Epoch 50/100\n",
      " - 2s - loss: 0.4197 - val_loss: 0.6394\n",
      "Epoch 51/100\n",
      " - 2s - loss: 0.4156 - val_loss: 0.6508\n",
      "Epoch 52/100\n",
      " - 2s - loss: 0.4178 - val_loss: 0.6191\n",
      "Epoch 53/100\n",
      " - 2s - loss: 0.4157 - val_loss: 0.6664\n",
      "Epoch 54/100\n",
      " - 2s - loss: 0.4130 - val_loss: 0.6630\n",
      "Epoch 55/100\n",
      " - 2s - loss: 0.4141 - val_loss: 0.6488\n",
      "Epoch 56/100\n",
      " - 2s - loss: 0.4142 - val_loss: 0.6909\n",
      "Epoch 57/100\n",
      " - 2s - loss: 0.4114 - val_loss: 0.6380\n",
      "Epoch 58/100\n",
      " - 2s - loss: 0.4101 - val_loss: 0.6378\n",
      "Epoch 59/100\n",
      " - 2s - loss: 0.4085 - val_loss: 0.6722\n",
      "Epoch 60/100\n",
      " - 2s - loss: 0.4072 - val_loss: 0.6633\n",
      "Epoch 61/100\n",
      " - 2s - loss: 0.4078 - val_loss: 0.6337\n",
      "Epoch 62/100\n",
      " - 2s - loss: 0.4064 - val_loss: 0.6705\n",
      "Epoch 63/100\n",
      " - 2s - loss: 0.4053 - val_loss: 0.6786\n",
      "Epoch 64/100\n",
      " - 2s - loss: 0.4035 - val_loss: 0.6304\n",
      "Epoch 65/100\n",
      " - 2s - loss: 0.4064 - val_loss: 0.6369\n",
      "Epoch 66/100\n",
      " - 2s - loss: 0.4047 - val_loss: 0.6116\n",
      "Epoch 67/100\n",
      " - 2s - loss: 0.4013 - val_loss: 0.6516\n",
      "Epoch 68/100\n",
      " - 2s - loss: 0.4025 - val_loss: 0.6377\n",
      "Epoch 69/100\n",
      " - 2s - loss: 0.4004 - val_loss: 0.6561\n",
      "Epoch 70/100\n",
      " - 2s - loss: 0.4007 - val_loss: 0.7062\n",
      "Epoch 71/100\n",
      " - 2s - loss: 0.3989 - val_loss: 0.6503\n",
      "Epoch 72/100\n",
      " - 2s - loss: 0.3979 - val_loss: 0.6820\n",
      "Epoch 73/100\n",
      " - 2s - loss: 0.3964 - val_loss: 0.6934\n",
      "Epoch 74/100\n",
      " - 2s - loss: 0.3977 - val_loss: 0.6383\n",
      "Epoch 75/100\n",
      " - 2s - loss: 0.3931 - val_loss: 0.6573\n",
      "Epoch 76/100\n",
      " - 2s - loss: 0.3943 - val_loss: 0.6225\n",
      "Epoch 77/100\n",
      " - 2s - loss: 0.3934 - val_loss: 0.6328\n",
      "Epoch 78/100\n",
      " - 2s - loss: 0.3954 - val_loss: 0.7056\n",
      "Epoch 79/100\n",
      " - 2s - loss: 0.3907 - val_loss: 0.7143\n",
      "Epoch 80/100\n",
      " - 2s - loss: 0.3909 - val_loss: 0.7284\n",
      "Epoch 81/100\n",
      " - 2s - loss: 0.3888 - val_loss: 0.6271\n",
      "Epoch 82/100\n",
      " - 2s - loss: 0.3903 - val_loss: 0.6443\n",
      "Epoch 83/100\n",
      " - 2s - loss: 0.3884 - val_loss: 0.6643\n",
      "Epoch 84/100\n",
      " - 2s - loss: 0.3898 - val_loss: 0.6811\n",
      "Epoch 85/100\n",
      " - 2s - loss: 0.3860 - val_loss: 0.6548\n",
      "Epoch 86/100\n",
      " - 2s - loss: 0.3858 - val_loss: 0.6386\n",
      "Epoch 87/100\n",
      " - 2s - loss: 0.3849 - val_loss: 0.6488\n",
      "Epoch 88/100\n",
      " - 2s - loss: 0.3844 - val_loss: 0.7113\n",
      "Epoch 89/100\n",
      " - 2s - loss: 0.3836 - val_loss: 0.6775\n",
      "Epoch 90/100\n",
      " - 2s - loss: 0.3822 - val_loss: 0.6588\n",
      "Epoch 91/100\n",
      " - 2s - loss: 0.3809 - val_loss: 0.6570\n",
      "Epoch 92/100\n",
      " - 2s - loss: 0.3802 - val_loss: 0.6885\n",
      "Epoch 93/100\n",
      " - 2s - loss: 0.3788 - val_loss: 0.6575\n",
      "Epoch 94/100\n",
      " - 2s - loss: 0.3782 - val_loss: 0.6850\n",
      "Epoch 95/100\n",
      " - 2s - loss: 0.3777 - val_loss: 0.6707\n",
      "Epoch 96/100\n",
      " - 2s - loss: 0.3757 - val_loss: 0.6536\n",
      "Epoch 97/100\n",
      " - 2s - loss: 0.3754 - val_loss: 0.6746\n",
      "Epoch 98/100\n",
      " - 2s - loss: 0.3747 - val_loss: 0.6635\n",
      "Epoch 99/100\n",
      " - 2s - loss: 0.3767 - val_loss: 0.6555\n",
      "Epoch 100/100\n",
      " - 2s - loss: 0.3740 - val_loss: 0.6739\n"
     ]
    }
   ],
   "source": [
    "print 'Slicing by:', SLICE_BY\n",
    "print 'Samples in slice:', len(x)\n",
    "print\n",
    "\n",
    "print 'Shape:', x.shape\n",
    "print 'Classes:', classes\n",
    "print\n",
    "\n",
    "def get_model():\n",
    "  model = Sequential()\n",
    "  model.add(Dense(units=512, activation='relu', input_dim=x.shape[1]))\n",
    "  model.add(Dropout(rate=0.7))\n",
    "  model.add(Dense(units=512, activation='relu'))\n",
    "  model.add(Dropout(rate=0.7))\n",
    "  model.add(Dense(units=256, activation='relu'))\n",
    "  model.add(Dropout(rate=0.7))\n",
    "  model.add(Dense(units=128, activation='relu'))\n",
    "  model.add(Dense(units=1))\n",
    "#   model.add(Lambda(lambda x: K.clip(x, min_value=1, max_value=5)))\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer='adadelta')\n",
    "  return model\n",
    "\n",
    "def shuffle(x, y):\n",
    "  assert(x.shape[0] == y.shape[0])\n",
    "  split = x.shape[1]\n",
    "  z = np.hstack((x, y))\n",
    "  z = np.random.permutation(z)\n",
    "  return z[:,:split], z[:,split:]\n",
    "  \n",
    "x_train, y_train = shuffle(x, np.reshape(y, (y.shape[0], 1)))\n",
    "model = get_model()\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=100, \n",
    "                    batch_size=128, \n",
    "                    validation_split=0.2,\n",
    "                    verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
